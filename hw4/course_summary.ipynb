{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "course_summary.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "snsr8vQVZDsj",
        "3jrblFUEZFtf",
        "iKZKtNTdahvZ",
        "RcPYfdZLeIk9",
        "DqnnkSJgZLCx",
        "ah4piWMFysvG",
        "prtzl8xSzFN1",
        "t5hZuPQzZOu7",
        "NvvyxDlb2BHs",
        "48V2y_8yZRJw",
        "DhPFsJCO-qsI",
        "IKX-NgPLZU89"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliawarner/ai_course/blob/master/hw4/course_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKmQEN4Y9uj",
        "colab_type": "text"
      },
      "source": [
        "Julia Warner\n",
        "\n",
        "CAP 4630\n",
        "\n",
        "HW4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snsr8vQVZDsj",
        "colab_type": "text"
      },
      "source": [
        "###### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZgh9NwFY6GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jrblFUEZFtf",
        "colab_type": "text"
      },
      "source": [
        "# General Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL8_xshjZbq8",
        "colab_type": "text"
      },
      "source": [
        "The most basic definition of **artificial intelligence** describes it as a branch of comupter science dedicated to creating machines/computers that are capable of simulating human intelligence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKZKtNTdahvZ",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p-KecF_ajoz",
        "colab_type": "text"
      },
      "source": [
        "**Machine learning** is the branch of AI development where the program will make adjustments to itself in response to its input data. A machine learning program changes itself and learns without needed a human to manually adjust it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TemT0NCrbMpc",
        "colab_type": "text"
      },
      "source": [
        "There are three categories of machine learning. \n",
        "\n",
        "\n",
        "\n",
        "1.   **Supervised Learning** where the program is provided with labeled training data that it uses to make connections between the data and the labels, learning how to assign the correct label to each datum. \n",
        "2.   **Unsupervised Learning** where the program is provided with unlabeled training data, so it must create its own categories based on data features it determines are important through learning. \n",
        "3.   **Reinforcement Learning** where the program learns what the correct course of action to take is through receiving rewards for positive actions and punishments for negative actions. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcPYfdZLeIk9",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlk2qfDGck-d",
        "colab_type": "text"
      },
      "source": [
        "Machine learning is often accomplished through the use of **neural networks**, which are programs comprised of **nodes** that input and output data and **weights** that pass the data from node to node. Learning is accomplished by changing the weights between nodes so that relevant data is given a heavier weight (greater importance) and irrelevant data is given a lower weight. The process of changing the weights of a neural network is called **training**. After the network is trained, it should produce the correct output for each given input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeqBbNY-eVO4",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.oracle.com/a/tech/img/art-neural-network-image002.png)\n",
        "\n",
        "*Image via oracle.com*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDalfqhUehB9",
        "colab_type": "text"
      },
      "source": [
        "The above diagram is an example of a neural network. The circles represent nodes and the arrows represent weights. Each column of nodes is called a **layer**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgzmV7hLdynX",
        "colab_type": "text"
      },
      "source": [
        " **Deep Learning** is a type of machine learning referring to neural networks with many layers of nodes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqnnkSJgZLCx",
        "colab_type": "text"
      },
      "source": [
        "# Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptdHLiq7fJBd",
        "colab_type": "text"
      },
      "source": [
        "In this section, keras will be used to create a neural network used to classify images of digits from the MNIST digit set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah4piWMFysvG",
        "colab_type": "text"
      },
      "source": [
        "#### Load and prep dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPuA3qu_ZOWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "\n",
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prtzl8xSzFN1",
        "colab_type": "text"
      },
      "source": [
        "##Adding layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHH2pH-BzNMG",
        "colab_type": "text"
      },
      "source": [
        "The code below uses keras to create a sequential neural network.\n",
        "\n",
        "Each layer has a **layer type** that determines how the weights attached to the nodes in that layer behave. The network created below consists of two **dense** layers. Dense layers receive input from all of the nodes in the previous layer. \n",
        "\n",
        "Each layer also has an **activation function** that determines whether or not each node is \"activated\", meaning that it passes its data on to the next layer. The first layer uses **relu** , a basic linear activation function, and the second layer uses **softmax**, an activation function used to turn the output of the network into probability values representing how well the data fits into each classification category. \n",
        "\n",
        "Each layer also has a size that determines the number of nodes in that layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyrSg6sAzDSl",
        "colab_type": "code",
        "outputId": "d748ebff-8c6c-431e-81b2-f529188fc9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6YsJyLO0xUa",
        "colab_type": "text"
      },
      "source": [
        "Another popular layer type not used in this example is a **convolutional layer**. Convolutional layers pass filters over the data in order to detect certain features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PoM2f9Z1cTD",
        "colab_type": "text"
      },
      "source": [
        "Different layer types, layer sizes, activation functions, and number of layers in your network all effect what features are detected and how they are detected. When completing a machine learning problem using a neural network, experiment with different combinations to see which works best. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5hZuPQzZOu7",
        "colab_type": "text"
      },
      "source": [
        "# Compiling a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PicQwTCj7fCw",
        "colab_type": "text"
      },
      "source": [
        "After the model is built, it is compiled using a single line of code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4VznKKa7aOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9biBI3uJ7j7u",
        "colab_type": "text"
      },
      "source": [
        "Three new parts of the model are introduced in this line. \n",
        "\n",
        "The **optimizer** determines the **learning rate** (explained below). Optimizers are necissary because they allow for a dynamic learning rate, which reduces the potential for overfitting. The optimizer used here is **rmsprop**, which selects a different learning rate for each parameter based on its needs, automatically adjusts those learning rates, and attempts to dampen oscillations (overshooting). Other popular optimizers are **Momentum**, which takes previous learning rates into consideration when adjusting learning rates, and **Adam**, which combines the strategies of both momentum and rmsprop. \n",
        "\n",
        "The **loss** determines how the correctness of the network's output will be determined. **Categorical crossentropy** is used for networks that produce a probability distribution as an output. It compares the probability generated for each possible category with the ground truth probability distribution, which will be 1 for the true category and 0 for all others.\n",
        "\n",
        "The **metrics** determine what the network will keep track of as it learns. **Accuracy** shows how good the model is as at correctly determining the category of the data. **Loss** represents how far off the model's output is from the ground truth output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvvyxDlb2BHs",
        "colab_type": "text"
      },
      "source": [
        "## Importance of Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I60NWmOF2DH6",
        "colab_type": "text"
      },
      "source": [
        "The **learning rate** helps determine how much each weight will be changed each time the weights are updated. In the most basic stochastic gradient descent example, the learning rate is multiplied by the loss to determine how much the weight should change. \n",
        "\n",
        "Having a learning rate that is too high will cause the weights to change too fast and by too great an amount, resulting in overshooting and missing the best possible weight. Having a learning rate this is too low means the weights won't change by a great enough amount each time they are updated. This will cause the training to take too long. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48V2y_8yZRJw",
        "colab_type": "text"
      },
      "source": [
        "# Training a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRoAkWsr67uq",
        "colab_type": "text"
      },
      "source": [
        "The below line of code initiates the training for the model. \n",
        "\n",
        "The **epochs** determine how long the model will train for. In each epoch, each peice of data in the training data set is passed through the network and learned from. The **batch size** determines how many peices of data are passed through the network before updating the weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAe4ePgs-YFu",
        "colab_type": "code",
        "outputId": "817573be-8ff7-461d-fbb0-c27a23736cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "epochs = 10\n",
        "history = network.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.2520 - acc: 0.9283 - val_loss: 0.1337 - val_acc: 0.9617\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1037 - acc: 0.9693 - val_loss: 0.0888 - val_acc: 0.9725\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0690 - acc: 0.9799 - val_loss: 0.0860 - val_acc: 0.9729\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0492 - acc: 0.9855 - val_loss: 0.0744 - val_acc: 0.9774\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0372 - acc: 0.9886 - val_loss: 0.0680 - val_acc: 0.9781\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.0633 - val_acc: 0.9813\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0217 - acc: 0.9935 - val_loss: 0.0653 - val_acc: 0.9822\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0706 - val_acc: 0.9810\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0644 - val_acc: 0.9815\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0100 - acc: 0.9971 - val_loss: 0.0799 - val_acc: 0.9793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPFsJCO-qsI",
        "colab_type": "text"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWL1wBjP-tQ7",
        "colab_type": "text"
      },
      "source": [
        "Two sets of data are used when creating a machine learning model: the **testing data** and the **training data**. \n",
        "\n",
        "The training data is what is used to change the weights in the model. Each piece of training data is pushed through the network, the loss is evaluated, and the weights are updated accordingly. \n",
        "\n",
        "The testing data is used to evaluate the effectiveness of the model on data that it hasn't seen before. Models have a tendency to memorize the training data and overfit, meaning it won't be able to correctly categorize data that it hasn't seen. Keeping an eye on the accuracy of the model on testing data can help prevent overfitting.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFp1zep8_Rze",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting and Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JndE6tsF_WEU",
        "colab_type": "text"
      },
      "source": [
        "**Overfitting** happens when a machine learning model has memorized the training data. Instead of generalizing about common features, the model recognizes each peice of training data and knows what category it belongs to. Models that overfit have a high training accuracy but a low testing accuracy. Overfitting is caused by training for too long or having a model that is too complex. \n",
        "\n",
        "**Underfitting** happens when a machine learning models cannot detect any useful features within the training data. The model is either too simple or has not been trained for long enough, so it either can't learn or didn't have a long enough time to learn anything meaningful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nkipocHAXaO",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing the training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBZSTOABDwoM",
        "colab_type": "text"
      },
      "source": [
        "It's always a good idea to create graphs of the model's accuracy and loss as training progressed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peBh088_Ah3e",
        "colab_type": "code",
        "outputId": "638c4a07-56d1-4e95-c067-d568a00c9bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc_values = history_dict['acc']\n",
        "test_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCzT/wdoHmjukYPV9AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjqZTpd1EEIW",
        "colab_type": "text"
      },
      "source": [
        "The graphs show a good amount of improvement for both loss and accuracy as the training progressed. Towards the end, the gap between the training and testing accuracy/loss started to increase. Training accuracy/loss continued to improve while it stagnated for the testing data. This is an indication of slight overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKX-NgPLZU89",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning a Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJGWd18WjScI",
        "colab_type": "text"
      },
      "source": [
        "The process of finetuning a pretrained model includes two steps: feature extraction and the actual finetuning itself. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKSsLd6fhpmB",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpEUbwJujZJJ",
        "colab_type": "text"
      },
      "source": [
        "**Feature Extraction** is the process of using the features detected in a pretrained model as a basis for your new model. \n",
        "\n",
        "Feature extraction is accomplished as follows:\n",
        "\n",
        "\n",
        "1.   Obtain a pre-trained model. Even if the model is detecting something completely different from what you're trying to detect, the intermediate layers before the final classification layers learn useful data features that can be applied to your goals. \n",
        "2.   Remove the top classification layers of the pre-trained model. \n",
        "3.   Freeze the layers of the pre-trained model. The weights on those layers are already set to effectively detect features, so you don't want to change them with new training just yet. \n",
        "4.   Add your own classification layers on top of the pre-trained base. The pre-trained base model will pass its features to your classification layers, helping your model attain better accuracy. \n",
        "5.   Train your model. The weights for your classifier will update and make use of the features extracted from the data by the pre-trained model. This will ensure better model accuracy than creating a model completely from scratch. \n",
        "\n",
        "After completing the deature extraction training, continue on to finetuning. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANWIIaxlkwMB",
        "colab_type": "text"
      },
      "source": [
        "##Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSIAQLD9k0uA",
        "colab_type": "text"
      },
      "source": [
        "**Finetuning** is the process of re-training the top layers of the pretrained model so that they are better fitted to your purposes. \n",
        "\n",
        "Finetuning is accomplished as follows:\n",
        "\n",
        "\n",
        "1.   Only finetune a model that has gone through the feature extraction process. If you were to finetune with your untrained classifier on top of the pretrained model, the weights would be off due to the randomization of weights in the untrained classifier. \n",
        "2.   Unfreeze the top layers of the pretrained model. Leave the lower layers untrainable because those layers detect useful general features. Only the upper level layers should be retrained because they are used to detect higher-level, specific features. \n",
        "3.   Retrain the model. The weights of the upper layers of the pre-trained model and those of your classifier will be altered. This will create better learning of specific features relevant to your classifier and improve accuracy. \n",
        "\n",
        "Once the fintuning process is complete, you model will have greater accuracy than a model created from scratch without feature exprection or finetuning. \n",
        "\n"
      ]
    }
  ]
}